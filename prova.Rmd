---
title: "PARTE 2"
date: "6/27/2022"
output: pdf_document
---

(in bocca al lupo!)

```{r,include=FALSE}
n <- 15; beta1 <- 10; beta2 <- 19.74; e <- rnorm(n,0,10); x <- rnorm(n, 200, 1) 
y <- beta1+beta2*x + e 
lin.mod <- lm(y~x)
confint(lin.mod)
beta2.hat <- cov(y,x)/var(x)
beta2.se <- sqrt(vcov(lin.mod)[2,2])
conf <- .95
a <- 1-conf
crit.a <- qt(a/2, df = n-2, lower.tail = F); ans.a <-  paste('[', round(beta2.hat - crit.a*beta2.se, 3), ';',  round(beta2.hat + crit.a*beta2.se,3), ']')

crit.b <- qt(a/2, df = n-1, lower.tail = F); ans.b <-  paste('[',round(beta2.hat - crit.b*beta2.se, 3), ';',  round(beta2.hat + crit.b*beta2.se,2), ']') 

crit.c <- qnorm(a/2, lower.tail = F); ans.c <-  paste('[', round(beta2.hat - crit.c*beta2.se, 3), ';',  round(beta2.hat + crit.c*beta2.se,3), ']') 
```

```{r}
random <- mean(rnorm(123))
```

`r random`

### Esercizio 8

Si è stimato il seguente modello del mercato del lavoro

\[ \log(wage_i) = \beta_0 + \beta_1 exper_i + \beta_2 exper_i^2 + age_i + e_i\]

```{r}
n <- 100; beta0 <- 1; beta.age <- 3
age <- rchisq(n, df = 50)
logWage <- log(rnorm(n, mean = 20, sd = 2))
# logWage <- log(rnorm(n, mean = beta0 + beta.age*age, sd = 2))
exper <- rchisq(n, df = 5)
lin.mod <- lm(logWage ~ exper + I(exper^2) + age)
summary(lin.mod)
```

Quali dei coefficienti sono statisticamente significativi?

```{=latex}
 \framebox(\textwidth,200){}
```


### Esercizio 9

Sulla base del risultato dell'esercizio 8, Il modello è statisticamente significativo? Scrivere

1. l'ipotesi che si sta verificando 
2. la statistica test di riferimento 
3. il risultato della decisione inferenziale

```{=latex}
 \framebox(\textwidth,200){}
```


### Esercizio 10

Sia \[ y = \beta_0 + \beta_1 x + e \] un generico modello di regressione e sia la figura sottostante il grafico dei residui. Si scelga quale tra le seguenti affermazioni è corretta:

a. I residui sono eteroschedastici perché $\hat \sigma^2_i = \sigma^2$.
b. i residui sono eteroschedastici perché $\hat \sigma^2_i = f(x_i)$
c. i residui sono omoschedastici
d. non è il grafico con cui si dovrebbe testare l'ipotesi

```{r}
n <- 600; sigma2 <- 10; gamma <- 2; beta0 = 1; beta1 <- 10
x <- rnorm(n, mean = 10, sd = 2)
e <- c()
for(i in 1:n) e[i] <- rnorm(1, mean = 0, sd = sqrt(sigma2*x[i]^gamma) )
y = beta0 + beta1*x + e
e.hat <- residuals(lm(y~x))
plot(x, e.hat, ylab = 'residuals')
lin.mod <- lm(log(e.hat^2) ~ log(x))
a1 <- coefficients(lin.mod)[1]
a2 <- coefficients(lin.mod)[2]
```

### Esercizio 11

Si riporta il test di Jarque bera. 
```{r}
tseries::jarque.bera.test(e.hat)
```

a. i residui non sono normali
b. i residui sono normali
c. i residui sono normali ma eteroschedastici
d. nessuna delle precedenti

### Esercizio 12
Si vuole verificare l'effetto di una tassa sulla birra sul tasso di mortalità di incidenti autostradali stimando il modello

\[ TassoMort_{it} = \beta_{1i} + \beta_{2}TassaBirra_{it} + e_{it} \]

Quale stimatore è necessario utilizzare data la specificazione?

a. pooled
b. effetti fissi
c. effetti random
d. Hausman-Tailor


```{r}
### Esercizio 13 
# Si riprenda l'esercizio 10. Si è poi stimato il seguente modello di regressione $\log(\hat e^2) =$ `r round(a1,3)` $+$ `r round(a2,3)` $\log(x)$. Si potrebbe dire che $\hat \sigma^2_i =$ `r round(exp(a1),2)` $x_i^{`r round(a2,3)`}$? Commentare
```




